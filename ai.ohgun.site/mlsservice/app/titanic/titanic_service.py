"""
íƒ€ì´íƒ€ë‹‰ ë°ì´í„° ì„œë¹„ìŠ¤
íŒë‹¤ìŠ¤, ë„˜íŒŒì´, ì‚¬ì´í‚·ëŸ°ì„ ì‚¬ìš©í•œ ë°ì´í„° ì²˜ë¦¬ ë° ë¨¸ì‹ ëŸ¬ë‹ ì„œë¹„ìŠ¤
"""
import sys
import os
import logging
from pathlib import Path
from typing import List, Dict, Optional, Any, ParamSpecArgs
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from icecream import ic
from tabulate import tabulate

# Windows í„°ë¯¸ë„ ì¸ì½”ë”© ì„¤ì •
if sys.platform == 'win32':
    os.system('chcp 65001 >nul 2>&1')  # UTF-8 ì¸ì½”ë”© ì„¤ì •
    if hasattr(sys.stdout, 'reconfigure'):
        sys.stdout.reconfigure(encoding='utf-8')
    if hasattr(sys.stderr, 'reconfigure'):
        sys.stderr.reconfigure(encoding='utf-8')

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# print() í•¨ìˆ˜ë¥¼ ë˜í•‘í•˜ì—¬ í•­ìƒ flushë˜ë„ë¡ í•¨ (Docker ë¡œê·¸ ì¦‰ì‹œ í‘œì‹œ)
_original_print = print
def print(*args, **kwargs):
    """print() í•¨ìˆ˜ ë˜í¼: í•­ìƒ flushí•˜ì—¬ Docker ë¡œê·¸ì— ì¦‰ì‹œ í‘œì‹œ"""
    kwargs.setdefault('flush', True)  # flush=True ê¸°ë³¸ê°’ ì„¤ì •
    _original_print(*args, **kwargs)

# ic() í•¨ìˆ˜ë„ ë˜í•‘í•˜ì—¬ ì¶œë ¥ì´ ì¦‰ì‹œ í‘œì‹œë˜ë„ë¡ í•¨
_original_ic = ic
def ic(*args, **kwargs):
    """ic() í•¨ìˆ˜ ë˜í¼: ì¶œë ¥ í›„ flushí•˜ì—¬ Docker ë¡œê·¸ì— ì¦‰ì‹œ í‘œì‹œ"""
    result = _original_ic(*args, **kwargs)
    # ic() ì¶œë ¥ í›„ ê°•ì œ flush
    sys.stdout.flush()
    sys.stderr.flush()
    return result

# ê³µí†µ ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))

# TitanicMethod import
from .titanic_method import TitanicMethod


class TitanicService:
    """
    íƒ€ì´íƒ€ë‹‰ ìŠ¹ê° ë°ì´í„° CRUD ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    Java ìŠ¤íƒ€ì¼ì˜ ì„œë¹„ìŠ¤ ë ˆì´ì–´ íŒ¨í„´ êµ¬í˜„
    """
    def __init__(self):
        pass
    
    def _print_dataframe_info(self, name: str, df: pd.DataFrame, stage: str = ""):
        """
        DataFrame ì •ë³´ë¥¼ í„°ë¯¸ë„ì— í‘œ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
        """
        print(f"\n{'='*80}")
        if stage:
            print(f"ğŸ“Š [{stage}] {name} ë°ì´í„° ìƒíƒœ")
        else:
            print(f"ğŸ“Š {name} ë°ì´í„° ìƒíƒœ")
        print(f"{'='*80}")
        
        # 1. ë°ì´í„° íƒ€ì… ì¶œë ¥
        print(f"\n[1] ë°ì´í„° íƒ€ì… (dtypes)")
        print("-" * 80)
        dtype_df = pd.DataFrame({
            'Column': df.dtypes.index,
            'Type': df.dtypes.values.astype(str)
        })
        print(tabulate(dtype_df, headers='keys', tablefmt='grid', showindex=False))
        
        # 2. ì»¬ëŸ¼ ëª©ë¡ ì¶œë ¥
        print(f"\n[2] ì»¬ëŸ¼ ëª©ë¡ (columns)")
        print("-" * 80)
        print(f"ì´ {len(df.columns)}ê°œ ì»¬ëŸ¼: {', '.join(df.columns.tolist())}")
        
        # 3. ìƒìœ„ 5ê°œ í–‰ ì¶œë ¥
        print(f"\n[3] ìƒìœ„ 5ê°œ í–‰")
        print("-" * 80)
        print(tabulate(df.head(5), headers='keys', tablefmt='grid', showindex=True))
        
        # 4. Null ê°’ ê°œìˆ˜ ì¶œë ¥
        print(f"\n[4] Null ê°’ ê°œìˆ˜")
        print("-" * 80)
        null_series = df.isnull().sum()
        null_df = pd.DataFrame({
            'Column': null_series.index,
            'Null Count': null_series.values
        })
        null_df = null_df[null_df['Null Count'] > 0]  # Nullì´ ìˆëŠ” ì»¬ëŸ¼ë§Œ í‘œì‹œ
        if len(null_df) > 0:
            print(tabulate(null_df, headers='keys', tablefmt='grid', showindex=False))
        else:
            print("âœ… Null ê°’ì´ ì—†ìŠµë‹ˆë‹¤!")
        
        # 5. ë°ì´í„° í¬ê¸° ì •ë³´
        print(f"\n[5] ë°ì´í„° í¬ê¸°")
        print("-" * 80)
        print(f"í–‰(Rows): {len(df):,}ê°œ")
        print(f"ì—´(Columns): {len(df.columns)}ê°œ")
        print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum() / 1024:.2f} KB")
        print()

    def preprogress(self):
        print("\n" + "="*80)
        print("ğŸš€ íƒ€ì´íƒ€ë‹‰ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘")
        print("="*80)
        ic("ğŸ˜ŠğŸ˜Š ì „ì²˜ë¦¬ ì‹œì‘")
        
        the_method = TitanicMethod()
        df_train = the_method.new_model('train.csv')
        df_test = the_method.new_model('test.csv')
        this_train = the_method.create_df(df_train, 'Survived')
        
        # test.csvì—ëŠ” Survived ì»¬ëŸ¼ì´ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì²´í¬
        if 'Survived' in df_test.columns:
            this_test = the_method.create_df(df_test, 'Survived')
        else:
            this_test = df_test  # Survived ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            print("â„¹ï¸  Test ë°ì´í„°ì—ëŠ” Survived ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤ (ì˜ˆì¸¡ìš© ë°ì´í„°)")
            ic("Test ë°ì´í„°ì—ëŠ” Survived ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤ (ì˜ˆì¸¡ìš© ë°ì´í„°)")
        
        # ì „ì²˜ë¦¬ ì „ ìƒíƒœ ì¶œë ¥
        print("\n" + "="*80)
        print("ğŸ“‹ [ì „ì²˜ë¦¬ ì „] ë°ì´í„° ìƒíƒœ")
        print("="*80)
        for name, data in [('Train', this_train), ('Test', this_test)]:
            # í„°ë¯¸ë„ ì¶œë ¥ (í‘œ í˜•ì‹)
            self._print_dataframe_info(name, data, "ì „ì²˜ë¦¬ ì „")
            # API/ë¡œê·¸ ì¶œë ¥ (icecream) - í„°ë¯¸ë„ì—ë„ ì¶œë ¥ë˜ë„ë¡ print()ë„ í•¨ê»˜ ì‚¬ìš©
            print(f'[IC] 1. {name} ì˜ type\n {data.dtypes} ')
            ic(f'1. {name} ì˜ type\n {data.dtypes} ')
            print(f'[IC] 2. {name} ì˜ columns\n {data.columns} ')
            ic(f'2. {name} ì˜ columns\n {data.columns} ')
            print(f'[IC] 3. {name} ì˜ ìƒìœ„ 5ê°œ í–‰\n {data.head(5).to_dict(orient="records")} ')
            ic(f'3. {name} ì˜ ìƒìœ„ 5ê°œ í–‰\n {data.head(5).to_dict(orient="records")} ')
            print(f'[IC] 4. {name} ì˜ null ì˜ ê°¯ìˆ˜\n {data.isnull().sum().to_dict()}ê°œ')
            ic(f'4. {name} ì˜ null ì˜ ê°¯ìˆ˜\n {data.isnull().sum().to_dict()}ê°œ')

        # Train, Test ë°ì´í„° ì „ì²˜ë¦¬
        print("\n" + "="*80)
        print("âš™ï¸  ì „ì²˜ë¦¬ ì§„í–‰ ì¤‘...")
        print("="*80)
        print("  - í”¼ì²˜ ì‚­ì œ: SibSp, Parch, Cabin, Ticket")
        drop_features = ['SibSp', 'Parch', 'Cabin', 'Ticket']
        this_train, this_test = the_method.drop_feature(this_train, this_test, *drop_features)
        
        print("  - Pclass Ordinal ì²˜ë¦¬")
        this_train, this_test = the_method.pclass_ordinal(this_train, this_test)
        
        print("  - Title Nominal ì²˜ë¦¬")
        this_train, this_test = the_method.title_nominal(this_train, this_test)
        
        print("  - Gender Nominal ì²˜ë¦¬")
        this_train, this_test = the_method.gender_nominal(this_train, this_test)
        
        print("  - Age Ratio ì²˜ë¦¬")
        this_train, this_test = the_method.age_ratio(this_train, this_test)
        
        print("  - Fare Ratio ì²˜ë¦¬")
        this_train, this_test = the_method.fare_ratio(this_train, this_test)
        
        print("  - Embarked Nominal ì²˜ë¦¬")
        this_train, this_test = the_method.embarked_nominal(this_train, this_test)
        
        print("  - Name ì»¬ëŸ¼ ì‚­ì œ")
        drop_features = ['Name']
        this_train, this_test = the_method.drop_feature(this_train, this_test, *drop_features)
        
        # ì „ì²˜ë¦¬ í›„ ìƒíƒœ ì¶œë ¥
        print("\n" + "="*80)
        print("âœ… [ì „ì²˜ë¦¬ ì™„ë£Œ] ë°ì´í„° ìƒíƒœ")
        print("="*80)
        ic("ğŸ˜ŠğŸ˜Š ì „ì²˜ë¦¬ ì™„ë£Œ")
        for name, data in [('Train', this_train), ('Test', this_test)]:
            # í„°ë¯¸ë„ ì¶œë ¥ (í‘œ í˜•ì‹)
            self._print_dataframe_info(name, data, "ì „ì²˜ë¦¬ í›„")
            # API/ë¡œê·¸ ì¶œë ¥ (icecream) - í„°ë¯¸ë„ì—ë„ ì¶œë ¥ë˜ë„ë¡ print()ë„ í•¨ê»˜ ì‚¬ìš©
            print(f'[IC] 1. {name} ì˜ type\n {data.dtypes} ')
            ic(f'1. {name} ì˜ type\n {data.dtypes} ')
            print(f'[IC] 2. {name} ì˜ columns\n {data.columns} ')
            ic(f'2. {name} ì˜ columns\n {data.columns} ')
            print(f'[IC] 3. {name} ì˜ ìƒìœ„ 5ê°œ í–‰\n {data.head(5).to_dict(orient="records")} ')
            ic(f'3. {name} ì˜ ìƒìœ„ 5ê°œ í–‰\n {data.head(5).to_dict(orient="records")} ')
            print(f'[IC] 4. {name} ì˜ null ì˜ ê°¯ìˆ˜\n {data.isnull().sum().to_dict()}ê°œ')
            ic(f'4. {name} ì˜ null ì˜ ê°¯ìˆ˜\n {data.isnull().sum().to_dict()}ê°œ')
        
        print("\n" + "="*80)
        print("ğŸ‰ ì „ì²˜ë¦¬ ì™„ë£Œ!")
        print("="*80 + "\n")
    
    def modeling(self):
        ic("ğŸ˜ŠğŸ˜Š ëª¨ë¸ë§ ì‹œì‘")

        #ë¡œì§€ìŠ¤í‹± íšŒê·€
        #NB
        #ë¨ë¤ í¬ë ˆìŠ¤íŠ¸
        #LGBM
        #SVM

        ic("ğŸ˜ŠğŸ˜Š ëª¨ë¸ë§ ì™„ë£Œ")

    def learning(self):
        logger.info("ğŸ˜ŠğŸ˜Š í•™ìŠµ ì‹œì‘")
        
        #ë¡œì§€ìŠ¤í‹± íšŒê·€
        #NB
        #ë¨ë¤ í¬ë ˆìŠ¤íŠ¸
        #LGBM
        #SVM

        logger.info("ğŸ˜ŠğŸ˜Š í•™ìŠµ ì™„ë£Œ")

    def evaluating(self):
        ic("ğŸ˜ŠğŸ˜Š í‰ê°€ ì‹œì‘")

        the_method = TitanicMethod()

        # 1) ë°ì´í„° ë¡œë“œ
        df_train = the_method.new_model('train.csv')

        # 2) ë ˆì´ë¸” ë¶„ë¦¬
        y_df = the_method.create_label(df_train, 'Survived')
        X_df = the_method.create_df(df_train, 'Survived')

        # 3) ë™ì¼ íŒŒì´í”„ë¼ì¸ ì „ì²˜ë¦¬ (train_df, test_df í˜•íƒœë¡œ ì²˜ë¦¬)
        dummy = X_df.copy()

        drop_features = ['SibSp', 'Parch', 'Cabin', 'Ticket']
        X_df, dummy = the_method.drop_feature(X_df, dummy, *drop_features)
        X_df, dummy = the_method.pclass_ordinal(X_df, dummy)
        X_df, dummy = the_method.title_nominal(X_df, dummy)
        X_df, dummy = the_method.gender_nominal(X_df, dummy)
        X_df, dummy = the_method.age_ratio(X_df, dummy)
        X_df, dummy = the_method.fare_ratio(X_df, dummy)
        X_df, dummy = the_method.embarked_nominal(X_df, dummy)

        if 'Name' in X_df.columns:
            X_df, dummy = the_method.drop_feature(X_df, dummy, 'Name')

        # 4) í•™ìŠµ/ê²€ì¦ ë¶„ë¦¬
        y = y_df.squeeze()
        X_train, X_val, y_train, y_val = train_test_split(
            X_df, y, test_size=0.2, random_state=42, stratify=y
        )

        # 5) ì—¬ëŸ¬ ëª¨ë¸ ê²€ì¦
        models = [
            ("DecisionTree", DecisionTreeClassifier(random_state=42)),
            ("RandomForest", RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)),
            ("GaussianNB", GaussianNB()),
            ("SVM_rbf", SVC(kernel='rbf', probability=True, random_state=42)),
            ("LogisticRegression", LogisticRegression(max_iter=1000, n_jobs=-1))
        ]

        for name, model in models:
            model.fit(X_train, y_train)
            y_pred = model.predict(X_val)
            acc = accuracy_score(y_val, y_pred)
            msg = f"{name} ê²€ì¦ ì •í™•ë„: {acc*100:.2f}%"
            logger.info(msg)
            ic(msg)

        logger.info("ğŸ˜ŠğŸ˜Š í‰ê°€ ì™„ë£Œ")
        ic("ğŸ˜ŠğŸ˜Š í‰ê°€ ì™„ë£Œ")

    def submit(self):
        """
        RandomForest ëª¨ë¸ë¡œ test.csv ì˜ˆì¸¡ í›„ Kaggle ì œì¶œìš© CSV ìƒì„±
        ì¶œë ¥: submission.csv (PassengerId, Survived)
        """
        ic("ğŸ˜ŠğŸ˜Š ì œì¶œ ì‹œì‘")
        logger.info("ğŸ˜ŠğŸ˜Š ì œì¶œ ì‹œì‘")

        the_method = TitanicMethod()

        # 1) train.csv ë¡œë“œ ë° ì „ì²˜ë¦¬ (ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµ)
        df_train = the_method.new_model('train.csv')
        y_train_full = the_method.create_label(df_train, 'Survived').squeeze()
        X_train_full = the_method.create_df(df_train, 'Survived')

        # 2) test.csv ë¡œë“œ (PassengerId ì €ì¥)
        df_test = the_method.new_model('test.csv')
        test_passenger_ids = df_test['PassengerId'].copy()
        X_test = df_test.copy()

        # 3) ë™ì¼ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì ìš© (train, test í•¨ê»˜ ì²˜ë¦¬)
        drop_features = ['SibSp', 'Parch', 'Cabin', 'Ticket']
        X_train_full, X_test = the_method.drop_feature(X_train_full, X_test, *drop_features)
        X_train_full, X_test = the_method.pclass_ordinal(X_train_full, X_test)
        X_train_full, X_test = the_method.title_nominal(X_train_full, X_test)
        X_train_full, X_test = the_method.gender_nominal(X_train_full, X_test)
        X_train_full, X_test = the_method.age_ratio(X_train_full, X_test)
        X_train_full, X_test = the_method.fare_ratio(X_train_full, X_test)
        X_train_full, X_test = the_method.embarked_nominal(X_train_full, X_test)

        if 'Name' in X_train_full.columns:
            X_train_full, X_test = the_method.drop_feature(X_train_full, X_test, 'Name')

        # 4) PassengerId ì œê±° (ëª¨ë¸ í•™ìŠµìš© í”¼ì²˜ì—ì„œ ì œì™¸)
        if 'PassengerId' in X_train_full.columns:
            X_train_full = X_train_full.drop(columns=['PassengerId'])
        if 'PassengerId' in X_test.columns:
            X_test = X_test.drop(columns=['PassengerId'])

        # 5) RandomForest ëª¨ë¸ í•™ìŠµ (ì „ì²´ train ë°ì´í„° ì‚¬ìš©)
        model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)
        model.fit(X_train_full, y_train_full)
        logger.info("RandomForest ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
        ic("RandomForest ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")

        # 6) test ë°ì´í„° ì˜ˆì¸¡
        y_pred = model.predict(X_test)
        logger.info(f"ì˜ˆì¸¡ ì™„ë£Œ: {len(y_pred)}ê°œ ìƒ˜í”Œ")
        ic(f"ì˜ˆì¸¡ ì™„ë£Œ: {len(y_pred)}ê°œ ìƒ˜í”Œ")

        # 7) Kaggle ì œì¶œìš© CSV ìƒì„±
        submission = pd.DataFrame({
            'PassengerId': test_passenger_ids,
            'Survived': y_pred
        })

        # 8) CSV íŒŒì¼ ì €ì¥
        output_path = Path(__file__).parent / 'submission.csv'
        submission.to_csv(output_path, index=False)
        logger.info(f"ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: {output_path}")
        ic(f"ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: {output_path}")

        # 9) ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
        logger.info(f"\nì œì¶œ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 10ê°œ):\n{submission.head(10).to_string(index=False)}")
        ic(submission.head(10))

        logger.info("ğŸ˜ŠğŸ˜Š ì œì¶œ ì™„ë£Œ")
        ic("ğŸ˜ŠğŸ˜Š ì œì¶œ ì™„ë£Œ")
        
        return {
            "status": "success",
            "output_file": str(output_path),
            "total_predictions": len(y_pred),
            "preview": submission.head(10).to_dict(orient='records')
        }